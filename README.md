
# ğŸ™ï¸ Mumbai House Price Prediction ğŸ ğŸ’¸

Predict **Mumbai residential property prices** using machine learning, based on structured listing features such as **area (sq ft)**, **BHK**, **property type**, **region/locality**, **availability**, and **property age**.

âœ… Reproducible pipeline (build dataset â†’ train â†’ evaluate)  
ğŸ“¦ Saved model artifact (`models/model.joblib`)  
ğŸ“Š Auto-generated metrics + plots (`reports/metrics.json`, `reports/figures/`)

---

## âœ¨ Badges (Stickers)
![Python](https://img.shields.io/badge/Python-3.x-blue)
![ML](https://img.shields.io/badge/Machine%20Learning-Regression-orange)
![scikit-learn](https://img.shields.io/badge/scikit--learn-OK-yellow)
![Status](https://img.shields.io/badge/Project-Active-brightgreen)

---

## ğŸ“Œ Problem
Given a set of property listing attributes, predict the **sale price** of residential properties in Mumbai.

This is a **regression** task (not classification), so evaluation uses:
- **MAE**
- **RMSE**
- **RÂ²**

---

## ğŸ§¾ Dataset (Columns)
The dataset includes:

- **bhk**: number of bedrooms/hall/kitchen (BHK)
- **type**: apartment / villa / independent house / studio apartment
- **locality**: locality name
- **area**: property area (sq ft)
- **region**: region of the property
- **status**: Ready to move / Under construction
- **age**: New / Resale / unknown (treated as missing)
- **price** and **price_unit**:
  - `L` = Lakh (1 Lakh = 100,000 INR)
  - `Cr` = Crore (1 Crore = 10,000,000 INR)

ğŸ¯ **Target**: price converted into **Lakh** (`price_lakh`) in the processed dataset.

---

## ğŸ—‚ï¸ Project Structure

```

.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ make_dataset.py     # build processed dataset
â”‚   â”œâ”€â”€ train.py            # train and save model
â”‚   â”œâ”€â”€ evaluate.py         # evaluate, save metrics + plots
â”‚   â”œâ”€â”€ predict.py          # inference with JSON input (optional)
â”‚   â””â”€â”€ utils.py            # helper functions
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # raw CSV files (input)
â”‚   â””â”€â”€ processed/          # processed dataset (output)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ model.joblib        # trained pipeline
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ metrics.json        # evaluation metrics
â”‚   â””â”€â”€ figures/            # evaluation plots
â”œâ”€â”€ notebooks/              # exploratory notebooks (EDA/cleaning/modeling)
â””â”€â”€ requirements.txt

````

---

## âš™ï¸ Setup

```bash
pip install -r requirements.txt
````

---

## ğŸš€ How to Run (End-to-End)

### 1ï¸âƒ£ Build the processed dataset

Creates: `data/processed/final.csv`

```bash
python -m src.make_dataset
```

### 2ï¸âƒ£ Train the model

Creates: `models/model.joblib`

```bash
python -m src.train
```

### 3ï¸âƒ£ Evaluate the model

Creates:

* `reports/metrics.json`
* `reports/figures/pred_vs_true.png`
* `reports/figures/residuals.png`

```bash
python -m src.evaluate
```

---

## ğŸ“ˆ Results (Current Run)

Test set size: **n_test = 515**

* âœ… **MAE**: 83.76 (Lakh)
* âœ… **RMSE**: 170.37 (Lakh)
* âœ… **RÂ²**: 0.3544

Saved in: `reports/metrics.json`

---

## ğŸ–¼ï¸ Outputs (Plots)

### Predicted vs True

![Predicted vs True](reports/figures/pred_vs_true.png)

### Residual Plot

![Residual Plot](reports/figures/residuals.png)

> If you donâ€™t see images on GitHub, ensure the PNG files exist and are committed (see the â€œDo I need images?â€ section below).

---

## ğŸ§  Modeling Notes

* Uses a **scikit-learn Pipeline**:

  * ğŸ§¹ Missing value handling (imputation)
  * ğŸ·ï¸ Categorical encoding (One-Hot)
  * ğŸŒ² Tree-based regressor (good baseline for mixed feature types)
* High-cardinality fields (like **locality**) are handled using frequency thresholding (`min_frequency`) to reduce sparsity.

---

## ğŸ” Limitations & Next Steps

* ğŸ§© Add richer features (amenities, exact geo-coordinates, building quality, parking, etc.)
* ğŸ§ª Add **K-Fold Cross Validation** and compare multiple models
* ğŸ“‰ Try **log-transform** of the target price (handle skew)
* ğŸ·ï¸ Better categorical handling (Target Encoding with leakage-safe CV)
* ğŸ•µï¸ Error analysis by region/type/area bins to understand model weaknesses

---

## â™»ï¸ Reproducibility

Run everything with:

```bash
pip install -r requirements.txt
python -m src.make_dataset
python -m src.train
python -m src.evaluate
```

---

## ğŸ§¾ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

---

## ğŸ¤ Contact

If you have feedback or suggestions, feel free to open an issue or reach out.


